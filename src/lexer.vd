import std/core;
import std/format;
import std/io;
import std/list;
import std/map;
import std/string;

import span;

enum TokenType: u8 {
	case Identifier;

	// literals
	case CharLiteral;
	case StringLiteral;
	case NumberLiteral;

	case LiteralPostfix;

	// structural tokens
	case LParen;					// (
	case RParen;					// )
	case LSquare;					// [
	case RSquare;					// ]
	case LCurly;					// {
	case RCurly;					// }

	case Comma;						// ,
	case Semicolon;					// ;
	case Dot;						// .
	case QuestionMark;				// ?
	case Colon;						// :
	case DoubleColon;				// ::
	case AtSign;					// @

	// operators
	case Assign;					// =
	case Plus;						// +
	case Minus;						// -
	case Asterisk;					// *
	case Slash;						// /
	case Percent;					// %
	case Ampersand;					// &
	case Pipe;						// |
	case Caret;						// ^
	case Tilde;						// ~
	case ExclamationMark;			// !
	case Arrow;						// ->
	case DoubleDot;					// ..
	case DoubleQuestionMark;		// ??
	case DoublePlus;				// ++
	case DoubleMinus;				// --
	case DoubleAmpersand;			// &&
	case DoublePipe;				// ||

	// comparison operators
	case Equal;						// ==
	case NotEqual;					// !=
	case LessThan;					// <
	case LessEqual;					// <=
	case GreaterThan;				// >
	case GreaterEqual;				// >=
	case Spaceship;					// <=>

	// assignment operators
	case ColonAssign;				// :=
	case PlusAssign;				// +=
	case MinusAssign;				// -=
	case AsteriskAssign;			// *=
	case SlashAssign;				// /=
	case PercentAssign;				// %=
	case AmpersandAssign;			// &=
	case PipeAssign;				// |=
	case CaretAssign;				// ^=
	case DoubleQuestionMarkAssign;	// ??=

	// keywords
	case KeywordAlias;
	case KeywordAs;
	case KeywordBreak;
	case KeywordCase;
	case KeywordComptime;
	case KeywordConst;
	case KeywordContinue;
	case KeywordDefault;
	case KeywordDiscard;
	case KeywordDo;
	case KeywordElse;
	case KeywordEnum;
	case KeywordExtern;
	case KeywordFalse;
	case KeywordFor;
	case KeywordFunc;
	case KeywordIf;
	case KeywordImport;
	case KeywordIn;
	case KeywordIs;
	case KeywordMatch;
	case KeywordMust;
	case KeywordNamespace;
	case KeywordOperator;
	case KeywordPragma;
	case KeywordPrivate;
	case KeywordPublic;
	case KeywordReturn;
	case KeywordStruct;
	case KeywordTemplate;
	case KeywordThrow;
	case KeywordTrue;
	case KeywordTry;
	case KeywordUnsafe;
	case KeywordUnwrap;
	case KeywordVar;
	case KeywordVariant;
	case KeywordWhile;
	case KeywordYield;
	case Unknown;
	case EndOfFile;

	func constructor(this: &&TokenType) -> void {
		this.constructor(TokenType::Unknown);
	}

	func toString(this: TokenType) -> String {
		match this {
			case Identifier -> return "<identifier>";
			case CharLiteral -> return "<char literal>";
			case StringLiteral -> return "<string literal>";
			case NumberLiteral -> return "<number literal>";
			case LiteralPostfix -> return "<literal postfix>";
			case LParen -> return "<token> (";
			case RParen -> return "<token> )";
			case LSquare -> return "<token> [";
			case RSquare -> return "<token> ]";
			case LCurly -> return "<token> {";
			case RCurly -> return "<token> }";
			case Comma -> return "<token> ,";
			case Semicolon -> return "<token> ;";
			case Dot -> return "<token> .";
			case QuestionMark -> return "<token> ?";
			case Colon -> return "<token> :";
			case DoubleColon -> return "<token> ::";
			case AtSign -> return "<token> @";
			case Assign -> return "<token> =";
			case Plus -> return "<token> +";
			case Minus -> return "<token> -";
			case Asterisk -> return "<token> *";
			case Slash -> return "<token> /";
			case Percent -> return "<token> %";
			case Ampersand -> return "<token> &";
			case Pipe -> return "<token> |";
			case Caret -> return "<token> ^";
			case Tilde -> return "<token> ~";
			case ExclamationMark -> return "<token> !";
			case Arrow -> return "<token> ->";
			case DoubleDot -> return "<token> ..";
			case DoubleQuestionMark -> return "<token> ??";
			case DoublePlus -> return "<token> ++";
			case DoubleMinus -> return "<token> --";
			case DoubleAmpersand -> return "<token> &&";
			case DoublePipe -> return "<token> ||";
			case Equal -> return "<token> ==";
			case NotEqual -> return "<token> !=";
			case LessThan -> return "<token> <";
			case LessEqual -> return "<token> <=";
			case GreaterThan -> return "<token> >";
			case GreaterEqual -> return "<token> >=";
			case Spaceship -> return "<token> <=>";
			case ColonAssign -> return "<token> :=";
			case PlusAssign -> return "<token> +=";
			case MinusAssign -> return "<token> -=";
			case AsteriskAssign -> return "<token> *=";
			case SlashAssign -> return "<token> /=";
			case PercentAssign -> return "<token> %=";
			case AmpersandAssign -> return "<token> &=";
			case PipeAssign -> return "<token> |=";
			case CaretAssign -> return "<token> ^=";
			case DoubleQuestionMarkAssign -> return "<token> ??=";
			case KeywordAlias -> return "<keyword> alias";
			case KeywordAs -> return "<keyword> as";
			case KeywordBreak -> return "<keyword> break";
			case KeywordCase -> return "<keyword> case";
			case KeywordComptime -> return "<keyword> comptime";
			case KeywordConst -> return "<keyword> const";
			case KeywordContinue -> return "<keyword> continue";
			case KeywordDefault -> return "<keyword> default";
			case KeywordDiscard -> return "<keyword> discard";
			case KeywordDo -> return "<keyword> do";
			case KeywordElse -> return "<keyword> else";
			case KeywordEnum -> return "<keyword> enum";
			case KeywordExtern -> return "<keyword> extern";
			case KeywordFalse -> return "<keyword> false";
			case KeywordFor -> return "<keyword> for";
			case KeywordFunc -> return "<keyword> func";
			case KeywordIf -> return "<keyword> if";
			case KeywordImport -> return "<keyword> import";
			case KeywordIn -> return "<keyword> in";
			case KeywordIs -> return "<keyword> is";
			case KeywordMatch -> return "<keyword> match";
			case KeywordMust -> return "<keyword> must";
			case KeywordNamespace -> return "<keyword> namespace";
			case KeywordOperator -> return "<keyword> operator";
			case KeywordPragma -> return "<keyword> pragma";
			case KeywordPrivate -> return "<keyword> private";
			case KeywordPublic -> return "<keyword> public";
			case KeywordReturn -> return "<keyword> return";
			case KeywordStruct -> return "<keyword> struct";
			case KeywordTemplate -> return "<keyword> template";
			case KeywordThrow -> return "<keyword> throw";
			case KeywordTrue -> return "<keyword> true";
			case KeywordTry -> return "<keyword> try";
			case KeywordUnsafe -> return "<keyword> unsafe";
			case KeywordUnwrap -> return "<keyword> unwrap";
			case KeywordVar -> return "<keyword> var";
			case KeywordVariant -> return "<keyword> variant";
			case KeywordWhile -> return "<kewyord> while";
			case KeywordYield -> return "<kewyord> yield";
			case Unknown -> return "<unknown>";
			case EndOfFile -> return "<eof>";
		}
	}
}

struct Token {
	var data: uint;
	var span: Span;

	func constructor(this: &&Token, token: TokenType, span: Span) -> void {
		this.data := token as uint;
		this.span := span;
	}

	func constructor(this: &&Token, token: TokenType, data: uint, span: Span) -> void {
		this.data := token as uint | (data << 8);
		this.span := span;
	}

	func constructor(this: &&Token, other: Token) -> void = default;
	func destructor(this: &&Token) -> void = default;

	operator =(this: &&Token, other: Token) -> void = default;
	operator ==(this: Token, other: Token) -> bool = default;

	func type(this: &Token) -> TokenType {
		return (this.data & 0xFF) as TokenType;
	}

	func data(this: &Token) -> uint {
		return this.data >> 8;
	}

	func toString(this: &Token) -> String {
		return this.type().toString();
	}

	func dump(this: &Token) -> String {
		return "\e[32m" + this.type().toString() + "\e[0m - " + this.span.dump() + "\n";
	}
}

func dump(tokens: &List!<Token>) -> String {
	var result = "";

	for tok in tokens {
		result += tok.dump();
	}

	return result;
}

struct Lexer {
	var src: String;

	var tokens: &&List!<Token>;
	var strings: &&List!<String>;
	var numbers: &&List!<ParsedNumber>;

	var keywords: Map!<String, TokenType>;

	var index: uint;
	var line_start: uint;
	var line: u32;
	var file_id: u16;

	func constructor(this: &&Lexer, tokens: &&List!<Token>, strings: &&List!<String>, numbers: &&List!<ParsedNumber>, src: &String, file_id: u16) -> void {
		this.src := src;
		this.tokens := &&tokens;
		this.strings := &&strings;
		this.numbers := &&numbers;

		this.keywords := ();
		this.keywords["alias"] = TokenType::KeywordAlias;
		this.keywords["as"] = TokenType::KeywordAs;
		this.keywords["break"] = TokenType::KeywordBreak;
		this.keywords["case"] = TokenType::KeywordCase;
		this.keywords["comptime"] = TokenType::KeywordComptime;
		this.keywords["const"] = TokenType::KeywordConst;
		this.keywords["continue"] = TokenType::KeywordContinue;
		this.keywords["default"] = TokenType::KeywordDefault;
		this.keywords["discard"] = TokenType::KeywordDiscard;
		this.keywords["do"] = TokenType::KeywordDo;
		this.keywords["else"] = TokenType::KeywordElse;
		this.keywords["enum"] = TokenType::KeywordEnum;
		this.keywords["extern"] = TokenType::KeywordExtern;
		this.keywords["false"] = TokenType::KeywordFalse;
		this.keywords["for"] = TokenType::KeywordFor;
		this.keywords["func"] = TokenType::KeywordFunc;
		this.keywords["if"] = TokenType::KeywordIf;
		this.keywords["import"] = TokenType::KeywordImport;
		this.keywords["in"] = TokenType::KeywordIn;
		this.keywords["is"] = TokenType::KeywordIs;
		this.keywords["match"] = TokenType::KeywordMatch;
		this.keywords["must"] = TokenType::KeywordMust;
		this.keywords["namespace"] = TokenType::KeywordNamespace;
		this.keywords["operator"] = TokenType::KeywordOperator;
		this.keywords["pragma"] = TokenType::KeywordPragma;
		this.keywords["private"] = TokenType::KeywordPrivate;
		this.keywords["public"] = TokenType::KeywordPublic;
		this.keywords["return"] = TokenType::KeywordReturn;
		this.keywords["struct"] = TokenType::KeywordStruct;
		this.keywords["template"] = TokenType::KeywordTemplate;
		this.keywords["throw"] = TokenType::KeywordThrow;
		this.keywords["true"] = TokenType::KeywordTrue;
		this.keywords["try"] = TokenType::KeywordTry;
		this.keywords["unsafe"] = TokenType::KeywordUnsafe;
		this.keywords["unwrap"] = TokenType::KeywordUnwrap;
		this.keywords["var"] = TokenType::KeywordVar;
		this.keywords["variant"] = TokenType::KeywordVariant;
		this.keywords["while"] = TokenType::KeywordWhile;
		this.keywords["yield"] = TokenType::KeywordYield;

		this.index := 0;
		this.line_start := 0;
		this.line := 0;
		this.file_id := file_id;
	}

	func constructor(this: &&Lexer, other: Lexer) -> void = default;
	func destructor(this: &&Lexer) -> void = default;

	func eof(this: &Lexer) -> bool {
		return this.index >= this.src.size();
	}

	func span(this: &Lexer, start: uint, end: uint) -> Span {
		return Span(start, end, this.line, (start - this.line_start) as u16, this.file_id);
	}

	func skipWhitespaceAndComments(this: &&Lexer) -> void {
		while this.index < this.src.size() {
			match this.src[this.index] {
				case ' 'b | '\t'b | '\r'b -> this.index++;
				case '\n'b -> {
					this.index++;
					this.line++;
					this.line_start = this.index;
				}
				case '/'b -> {
					if this.index + 1 >= this.src.size() {
						break;
					}

					if this.src[this.index + 1] == '/'b {
						this.skipSinglelineComment();
					} else if this.src[this.index + 1] == '*'b {
						this.skipMultilineComment();
					} else {
						break;
					}
				}
				else -> break;
			}
		}
	}

	func skipSinglelineComment(this: &&Lexer) -> void {
		this.index += 2;

		while this.index < this.src.size() {
			if this.src[this.index] == '\n'b {
				break;
			} else {
				this.index++;
			}
		}
	}

	func skipMultilineComment(this: &&Lexer) -> void {
		this.index += 2;

		var comment_completed = false;
		while this.index + 1 < this.src.size() {
			if this.src[this.index] == '*'b && this.src[this.index + 1] == '/'b {
				this.index += 2;
				comment_completed = true;
				break;
			} else {
				if this.src[this.index] == '\n'b {
					this.line++;
					this.line_start = this.index;
				}

				this.index++;
			}
		}

		// if multiline comment wasn't properly completed with */ skip until end of file
		if !comment_completed {
			this.index = this.src.size();
		}
	}

	func next(this: &&Lexer) -> void {
		this.skipWhitespaceAndComments();

		if this.index >= this.src.size() {
			return;
		}

		const start = this.index;
		match this.src[this.index] {
			case '('b -> {
				this.index++;
				this.tokens.append(Token(TokenType::LParen, this.span(start, this.index)));
			}
			case ')'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::RParen, this.span(start, this.index)));
			}
			case '['b -> {
				this.index++;
				this.tokens.append(Token(TokenType::LSquare, this.span(start, this.index)));
			}
			case ']'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::RSquare, this.span(start, this.index)));
			}
			case '{'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::LCurly, this.span(start, this.index)));
			}
			case '}'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::RCurly, this.span(start, this.index)));
			}
			case ','b -> {
				this.index++;
				this.tokens.append(Token(TokenType::Comma, this.span(start, this.index)));
			}
			case ';'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::Semicolon, this.span(start, this.index)));
			}
			case '@'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::AtSign, this.span(start, this.index)));
			}
			case '~'b -> {
				this.index++;
				this.tokens.append(Token(TokenType::Tilde, this.span(start, this.index)));
			}
			case '.'b -> this.tokens.append(this.lexDot());
			case '?'b -> this.tokens.append(this.lexQuestionmark());
			case ':'b -> this.tokens.append(this.lexColon());
			case '='b -> this.tokens.append(this.lexEqual());
			case '+'b -> this.tokens.append(this.lexPlus());
			case '-'b -> this.tokens.append(this.lexMinus());
			case '*'b -> this.tokens.append(this.lexAsterisk());
			case '/'b -> this.tokens.append(this.lexSlash());
			case '%'b -> this.tokens.append(this.lexPercent());
			case '&'b -> this.tokens.append(this.lexAmpersand());
			case '|'b -> this.tokens.append(this.lexPipe());
			case '^'b -> this.tokens.append(this.lexCaret());
			case '<'b -> this.tokens.append(this.lexLess());
			case '>'b -> this.tokens.append(this.lexGreater());
			case '!'b -> this.tokens.append(this.lexExclamationMark());
			case '\''b -> this.lexCharLiteral();
			case '"'b -> this.lexStringLiteral();
			else -> if isDigit(this.src[this.index]) {
				this.lexNumber();
			} else if isAlpha(this.src[this.index]) || this.src[this.index] == '_'b || this.src[this.index] > 127 {
				this.lexName();
			} else {
				this.index++;
				this.tokens.append(Token(TokenType::Unknown, this.span(start, this.index)));
			}
		}
	}

	func lexDot(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '.'b {
			this.index += 2;
			return Token(TokenType::DoubleDot, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Dot, this.span(this.index - 1, this.index));
		}
	}

	func lexQuestionmark(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '?'b {
			if this.src.at(this.index + 2) ?? '\0'b == '='b {
				this.index += 3;
				return Token(TokenType::DoubleQuestionMarkAssign, this.span(this.index - 3, this.index));
			} else {
				this.index += 2;
				return Token(TokenType::DoubleQuestionMark, this.span(this.index - 2, this.index));
			}
		} else {
			this.index += 1;
			return Token(TokenType::QuestionMark, this.span(this.index - 1, this.index));
		}
	}

	func lexColon(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == ':'b {
			this.index += 2;
			return Token(TokenType::DoubleColon, this.span(this.index - 2, this.index));
		} else if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::ColonAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Colon, this.span(this.index - 1, this.index));
		}
	}

	func lexEqual(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::Equal, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Assign, this.span(this.index - 1, this.index));
		}
	}

	func lexPlus(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '+'b {
			this.index += 2;
			return Token(TokenType::DoublePlus, this.span(this.index - 2, this.index));
		} else if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::PlusAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Plus, this.span(this.index - 1, this.index));
		}
	}

	func lexMinus(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '-'b {
			this.index += 2;
			return Token(TokenType::DoubleMinus, this.span(this.index - 2, this.index));
		} else if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::MinusAssign, this.span(this.index - 2, this.index));
		} else if this.src.at(this.index + 1) ?? '\0'b == '>'b {
			this.index += 2;
			return Token(TokenType::Arrow, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Minus, this.span(this.index - 1, this.index));
		}
	}

	func lexAsterisk(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::AsteriskAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Asterisk, this.span(this.index - 1, this.index));
		}
	}

	func lexSlash(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::SlashAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Slash, this.span(this.index - 1, this.index));
		}
	}

	func lexPercent(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::PercentAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Percent, this.span(this.index - 1, this.index));
		}
	}

	func lexAmpersand(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '&'b {
			this.index += 2;
			return Token(TokenType::DoubleAmpersand, this.span(this.index - 2, this.index));
		} else if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::AmpersandAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Ampersand, this.span(this.index - 1, this.index));
		}
	}

	func lexPipe(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '|'b {
			this.index += 2;
			return Token(TokenType::DoublePipe, this.span(this.index - 2, this.index));
		} else if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::PipeAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Pipe, this.span(this.index - 1, this.index));
		}
	}

	func lexCaret(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::CaretAssign, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::Caret, this.span(this.index - 1, this.index));
		}
	}

	func lexLess(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			if this.src.at(this.index + 2) ?? '\0'b == '>'b {
				this.index += 3;
				return Token(TokenType::Spaceship, this.span(this.index - 3, this.index));
			} else {
				this.index += 2;
				return Token(TokenType::LessEqual, this.span(this.index - 2, this.index));
			}
		} else {
			this.index += 1;
			return Token(TokenType::LessThan, this.span(this.index - 1, this.index));
		}
	}

	func lexGreater(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::GreaterEqual, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::GreaterThan, this.span(this.index - 1, this.index));
		}
	}

	func lexExclamationMark(this: &&Lexer) -> Token {
		if this.src.at(this.index + 1) ?? '\0'b == '='b {
			this.index += 2;
			return Token(TokenType::NotEqual, this.span(this.index - 2, this.index));
		} else {
			this.index += 1;
			return Token(TokenType::ExclamationMark, this.span(this.index - 1, this.index));
		}
	}

	func lexEscapedString(this: &&Lexer, end: byte) -> String {
		const start = this.index;
		var result = "";

		while this.index < this.src.size() {
			if this.src[this.index] == end {
				break;
			}

			if this.src[this.index] == '\\'b {
				this.index++;
				if this.index >= this.src.size() {
					break;
				}

				match this.src[this.index] {
					case '0'b -> result += '\0'b;
					case 'a'b -> result += '\a'b;
					case 'b'b -> result += '\b'b;
					case 'e'b -> result += '\e'b;
					case 'f'b -> result += '\f'b;
					case 'n'b -> result += '\n'b;
					case 'r'b -> result += '\r'b;
					case 't'b -> result += '\t'b;
					case 'v'b -> result += '\v'b;
					case '\\'b -> result += '\\'b;
					case '\''b -> result += '\''b;
					case '\"'b -> result += '\"'b;
					case '\?'b -> result += '\?'b;
					else -> panic("unknown escape sequence: '" + this.src[this.index] + "'");
				}

				this.index++;
			} else {
				result += this.src[this.index];
				this.index++;
			}
		}

		return result;
	}

	func lexPostfix(this: &&Lexer) -> String {
		const start = this.index;
		while this.index < this.src.size() {
			if !isWordChar(this.src[this.index]) {
				break;
			}

			this.index++;
		}
		return this.src.substring(start..this.index);
	}

	func lexCharLiteral(this: &&Lexer) -> void {
		const start = this.index;

		this.index++; // skip '
		const str = this.lexEscapedString('\''b);
		this.index++; // skip '

		const postfix = this.lexPostfix();
		const span = this.span(start, this.index);

		this.tokens.append(Token(TokenType::CharLiteral, str[0u] as uint, span));

		if !postfix.isEmpty() {
			this.tokens.append(Token(TokenType::LiteralPostfix, this.strings.size(), span));
			this.strings.append(postfix);
		}
	}

	func lexStringLiteral(this: &&Lexer) -> void {
		const start = this.index;

		this.index++; // skip "
		const str = this.lexEscapedString('\"'b);
		this.index++; // skip "

		const postfix = this.lexPostfix();
		const span = this.span(start, this.index);

		this.tokens.append(Token(TokenType::StringLiteral, this.strings.size(), span));
		this.strings.append(str);

		if !postfix.isEmpty() {
			this.tokens.append(Token(TokenType::LiteralPostfix, this.strings.size(), span));
			this.strings.append(postfix);
		}
	}

	func lexNumber(this: &&Lexer) -> void {
		const start = this.index;
		const parsed_number = parseNumber(this.src, start);
		assert(parsed_number.length != 0);

		this.index += parsed_number.length;

		const postfix = this.lexPostfix();
		const span = this.span(start, this.index);

		this.tokens.append(Token(TokenType::NumberLiteral, this.numbers.size(), span));
		this.numbers.append(parsed_number);

		if !postfix.isEmpty() {
			this.tokens.append(Token(TokenType::LiteralPostfix, this.strings.size(), span));
			this.strings.append(postfix);
		}
	}

	func lexName(this: &&Lexer) -> void {
		const start = this.index;

		while this.index < this.src.size() {
			if !isWordChar(this.src[this.index]) {
				break;
			}

			this.index++;
		}

		const name = this.src.substring(start..this.index);
		const span = this.span(start, this.index);

		match this.keywords.get(name) {
			case Some: keyword_id -> this.tokens.append(Token(keyword_id, span));
			else -> {
				this.tokens.append(Token(TokenType::Identifier, this.strings.size(), span));
				this.strings.append(name);
			}
		}
	}

	func isWordChar(char: byte) -> bool {
		return isAlpha(char) || isDigit(char) || char == '_'b || char > 127;
	}
}
