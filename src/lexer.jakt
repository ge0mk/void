import utility {Span, CompilerOptions, FileInfo, printError }

enum Token {
	span: Span

	Identifier(name: String)
	IntLiteral(value: i64, postfix: String)
	FloatLiteral(value: f64, postfix: String)
	CharLiteral(value: u8, postfix: String)
	StringLiteral(value: String, postfix: String)

	LParen
	RParen
	LSquare
	RSquare
	LCurly
	RCurly
	Dot
	Comma
	Colon
	AtSign
	Namespace
	Semicolon
	QuestionMark
	Range
	Arrow
	Assign
	Initialize
	Add
	Sub
	Mul
	Div
	Mod
	And
	Or
	Xor
	Not
	LogicalAnd
	LogicalOr
	LogicalNot
	Coalescing
	Increment
	Decrement
	AddAssign
	SubAssign
	MulAssign
	DivAssign
	ModAssign
	AndAssign
	OrAssign
	XorAssign
	CoalescingAssign
	Equal
	NotEqual
	GreaterThan
	GreaterEqual
	LessThan
	LessEqual
	Spaceship

	KeywordImport
	KeywordPragma

	KeywordExtern
	KeywordFunc
	KeywordOperator
	KeywordDefault

	KeywordTemplate
	KeywordStruct
	KeywordEnum
	KeywordVariant
	KeywordExtend

	KeywordPublic
	KeywordPrivate
	KeywordUnsafe

	KeywordVar
	KeywordConst
	KeywordCase

	KeywordComptime
	KeywordIs
	KeywordAs
	KeywordUnwrap

	KeywordIf
	KeywordElse
	KeywordFor
	KeywordIn
	KeywordWhile
	KeywordDo
	KeywordMatch

	KeywordContinue
	KeywordBreak
	KeywordReturn
	KeywordDiscard
	KeywordThrow

	KeywordTry
	KeywordMust

	KeywordTrue
	KeywordFalse

	Unknown(ch: u8)

	fn dump(this) throws -> String {
		let result = match this {
			Identifier(name) => "<id> " + name
			IntLiteral(value) => format("<int> {}", value)
			FloatLiteral(value) => format("<float> {}", value)
			CharLiteral(value) => format("<char> {}", value)
			StringLiteral(value) => format("<string> \"{}\"", value)
			LParen => "<token> ("
			RParen => "<token> )"
			LSquare => "<token> ["
			RSquare => "<token> ]"
			LCurly => "<token> {"
			RCurly => "<token> }"
			Dot => "<token> ."
			Comma => "<token> ,"
			Colon => "<token> :"
			AtSign => "<token> @"
			Namespace => "<token> ::"
			Semicolon => "<token> ;"
			QuestionMark => "<token> ?"
			Range => "<token> .."
			Arrow => "<token> ->"
			Assign => "<token> ="
			Initialize => "<token> :="
			Add => "<token> +"
			Sub => "<token> -"
			Mul => "<token> *"
			Div => "<token> /"
			Mod => "<token> %"
			And => "<token> &"
			Or => "<token> |"
			Xor => "<token> ^"
			Not => "<token> ~"
			LogicalAnd => "<token> &&"
			LogicalOr => "<token> ||"
			LogicalNot => "<token> !"
			Coalescing => "<token> ??"
			Increment => "<token> ++"
			Decrement => "<token> --"
			AddAssign => "<token> +="
			SubAssign => "<token> -="
			MulAssign => "<token> *="
			DivAssign => "<token> /="
			ModAssign => "<token> %="
			AndAssign => "<token> &="
			OrAssign => "<token> |="
			XorAssign => "<token> ^="
			CoalescingAssign => "<token> ??="
			Equal => "<token> =="
			NotEqual => "<token> !="
			GreaterThan => "<token> >"
			GreaterEqual => "<token> >="
			LessThan => "<token> <"
			LessEqual => "<token> <="
			Spaceship => "<token> <=>"
			KeywordImport => "<keyword> import"
			KeywordPragma => "<keyword> pragma"
			KeywordExtern => "<keyword> extern"
			KeywordFunc => "<keyword> func"
			KeywordOperator => "<keyword> operator"
			KeywordDefault => "<keyword> default"
			KeywordTemplate => "<keyword> template"
			KeywordStruct => "<keyword> struct"
			KeywordEnum => "<keyword> enum"
			KeywordVariant => "<keyword> variant"
			KeywordExtend => "<keyword> extend"
			KeywordPublic => "<keyword> public"
			KeywordPrivate => "<keyword> private"
			KeywordUnsafe => "<keyword> unsafe"
			KeywordVar => "<keyword> var"
			KeywordConst => "<keyword> const"
			KeywordCase => "<keyword> case"
			KeywordComptime => "<keyword> comptime"
			KeywordIs => "<keyword> is"
			KeywordAs => "<keyword> as"
			KeywordUnwrap => "<keyword> unwrap"
			KeywordIf => "<keyword> if"
			KeywordElse => "<keyword> else"
			KeywordFor => "<keyword> for"
			KeywordIn => "<keyword> in"
			KeywordWhile => "<keyword> while"
			KeywordDo => "<keyword> do"
			KeywordMatch => "<keyword> match"
			KeywordContinue => "<keyword> continue"
			KeywordBreak => "<keyword> break"
			KeywordReturn => "<keyword> return"
			KeywordDiscard => "<keyword> discard"
			KeywordThrow => "<keyword> throw"
			KeywordTry => "<keyword> try"
			KeywordMust => "<keyword> must"
			KeywordTrue => "<keyword> true"
			KeywordFalse => "<keyword> false"
			Unknown(ch) => format("<unknown> {}", ch)
		}

		return result + " " + .span.format()
	}

	fn toString(this) throws -> String => match this {
		Identifier(name) => name
		IntLiteral(value) => format("{}", value)
		FloatLiteral(value) => format("{}", value)
		CharLiteral(value) => format("{}", value)
		StringLiteral(value) => format("\"{}\"", value)
		LParen => "("
		RParen => ")"
		LSquare => "["
		RSquare => "]"
		LCurly => "{"
		RCurly => "}"
		Dot => "."
		Comma => ","
		Colon => ":"
		AtSign => "@"
		Namespace => "::"
		Semicolon => ";"
		QuestionMark => "?"
		Range => ".."
		Arrow => "->"
		Assign => "="
		Initialize => ":="
		Add => "+"
		Sub => "-"
		Mul => "*"
		Div => "/"
		Mod => "%"
		And => "&"
		Or => "|"
		Xor => "^"
		Not => "~"
		LogicalAnd => "&&"
		LogicalOr => "||"
		LogicalNot => "!"
		Coalescing => "??"
		Increment => "++"
		Decrement => "--"
		AddAssign => "+="
		SubAssign => "-="
		MulAssign => "*="
		DivAssign => "/="
		ModAssign => "%="
		AndAssign => "&="
		OrAssign => "|="
		XorAssign => "^="
		CoalescingAssign => "??="
		Equal => "=="
		NotEqual => "!="
		GreaterThan => ">"
		GreaterEqual => ">="
		LessThan => "<"
		LessEqual => "<="
		Spaceship => "<=>"
		KeywordImport => "import"
		KeywordPragma => "pragma"
		KeywordExtern => "extern"
		KeywordFunc => "func"
		KeywordOperator => "operator"
		KeywordDefault => "default"
		KeywordTemplate => "template"
		KeywordStruct => "struct"
		KeywordEnum => "enum"
		KeywordVariant => "variant"
		KeywordExtend => "extend"
		KeywordPublic => "public"
		KeywordPrivate => "private"
		KeywordUnsafe => "unsafe"
		KeywordVar => "var"
		KeywordConst => "const"
		KeywordCase => "case"
		KeywordComptime => "comptime"
		KeywordIs => "is"
		KeywordAs => "as"
		KeywordUnwrap => "unwrap"
		KeywordIf => "if"
		KeywordElse => "else"
		KeywordFor => "for"
		KeywordIn => "in"
		KeywordWhile => "while"
		KeywordDo => "do"
		KeywordMatch => "match"
		KeywordContinue => "continue"
		KeywordBreak => "break"
		KeywordReturn => "return"
		KeywordDiscard => "discard"
		KeywordThrow => "throw"
		KeywordTry => "try"
		KeywordMust => "must"
		KeywordTrue => "true"
		KeywordFalse => "false"
		Unknown(ch) => format("{}", ch)
	}
}

fn isSpace(anon ch: u8) -> bool {
	return (ch == b' ') or (ch == b'\t') or (ch == b'\n')
}

fn isDigit(anon ch: u8) -> bool {
	return (ch >= b'0') and (ch <= b'9')
}

fn isAlpha(anon ch: u8) -> bool {
	return ((ch >= b'A') and (ch <= b'Z')) or ((ch >= b'a') and (ch <= b'z'))
}

fn isAlphaOrDigit(anon ch: u8) -> bool {
	return isAlpha(ch) or isDigit(ch)
}

struct Lexer {
	options: CompilerOptions
	file: FileInfo
	source: [u8]
	index: usize

	fn lex(options: CompilerOptions, file: FileInfo, source: [u8]) throws -> [Token] {
		mut lexer = Lexer(options, file, source, index: 0)
		mut tokens: [Token] = []

		mut token = lexer.next()
		while token.has_value() {
			tokens.push(token!)
			token = lexer.next()
		}

		return tokens
	}

	fn error(this, anon message: String, anon span: Span) throws {
		printError(message, span, .file)
	}

	fn eof(this) -> bool {
		return .index >= .source.size()
	}

	fn span(this, anon start: usize, anon end: usize) -> Span {
		return Span(start, end)
	}

	fn next(mut this) throws -> Token? {
		while not .eof() {
			while (.index < .source.size()) and isSpace(.source[.index]) {
				.index++
			}

			if .eof() {
				return None
			}

			let start = .index
			match .source[.index] {
				b'(' => { return Token::LParen(span: .span(start, ++.index)) }
				b')' => { return Token::RParen(span: .span(start, ++.index)) }
				b'[' => { return Token::LSquare(span: .span(start, ++.index)) }
				b']' => { return Token::RSquare(span: .span(start, ++.index)) }
				b'{' => { return Token::LCurly(span: .span(start, ++.index)) }
				b'}' => { return Token::RCurly(span: .span(start, ++.index)) }
				b',' => { return Token::Comma(span: .span(start, ++.index)) }
				b';' => { return Token::Semicolon(span: .span(start, ++.index)) }
				b'@' => { return Token::AtSign(span: .span(start, ++.index)) }
				b'~' => { return Token::Not(span: .span(start, ++.index)) }
				b'.' => { return .lexDot() }
				b'?' => { return .lexQuestionmark() }
				b':' => { return .lexColon() }
				b'=' => { return .lexEqual() }
				b'+' => { return .lexPlus() }
				b'-' => { return .lexMinus() }
				b'*' => { return .lexMul() }
				b'/' => {
					if .source[.index + 1] == b'/' {
						.index += 2
						while not .eof() and .source[.index] != b'\n' {
							.index++
						}
						.index++
					} else if .source[.index + 1] == b'*' {
						.index += 2
						while not .eof() and ((.source[.index] != b'*') or (.source[.index + 1] != b'/')) {
							.index++
						}
						.index += 2
					} else {
						return .lexSlash()
					}
				}
				b'%' => { return .lexMod() }
				b'&' => { return .lexAnd() }
				b'|' => { return .lexOr() }
				b'^' => { return .lexXOr() }
				b'<' => { return .lexLess() }
				b'>' => { return .lexGreater() }
				b'!' => { return .lexNot() }
				b'\'' => { return .lexCharLiteral() }
				b'"' => { return .lexStringLiteral() }
				else => { return .lexNumberOrName() }
			}
		}

		return None
	}

	fn lexDot(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'.' {
			.index += 2
			return Token::Range(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Dot(span: .span(start, .index))
		}
	}

	fn lexQuestionmark(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'?' {
			if .source[.index + 2] == b'=' {
				.index += 3
				return Token::CoalescingAssign(span: .span(start, .index))
			} else {
				.index += 2
				return Token::Coalescing(span: .span(start, .index))
			}
		} else {
			.index += 1
			return Token::QuestionMark(span: .span(start, .index))
		}
	}

	fn lexColon(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b':' {
			.index += 2
			return Token::Namespace(span: .span(start, .index))
		} else if .source[.index + 1] == b'=' {
			.index += 2
			return Token::Initialize(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Colon(span: .span(start, .index))
		}
	}

	fn lexEqual(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::Equal(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Assign(span: .span(start, .index))
		}
	}

	fn lexPlus(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'+' {
			.index += 2
			return Token::Increment(span: .span(start, .index))
		} else if .source[.index + 1] == b'=' {
			.index += 2
			return Token::AddAssign(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Add(span: .span(start, .index))
		}
	}

	fn lexMinus(mut this) throws -> Token {
		let start = .index
		if .source[.index + 1] == b'-' {
			.index += 2
			return Token::Decrement(span: .span(start, .index))
		} else if .source[.index + 1] == b'=' {
			.index += 2
			return Token::SubAssign(span: .span(start, .index))
		} else if .source[.index + 1] == b'>' {
			.index += 2
			return Token::Arrow(span: .span(start, .index))
		} else if isDigit(.source[.index + 1]) {
			return .lexNumber()
		} else {
			.index += 1
			return Token::Sub(span: .span(start, .index))
		}
	}

	fn lexMul(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::MulAssign(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Mul(span: .span(start, .index))
		}
	}

	fn lexSlash(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::DivAssign(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Div(span: .span(start, .index))
		}
	}

	fn lexMod(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::ModAssign(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Mod(span: .span(start, .index))
		}
	}

	fn lexAnd(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::AndAssign(span: .span(start, .index))
		} else if .source[.index + 1] == b'&' {
			.index += 2
			return Token::LogicalAnd(span: .span(start, .index))
		} else {
			.index += 1
			return Token::And(span: .span(start, .index))
		}
	}

	fn lexOr(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::OrAssign(span: .span(start, .index))
		} else if .source[.index + 1] == b'|' {
			.index += 2
			return Token::LogicalOr(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Or(span: .span(start, .index))
		}
	}

	fn lexXOr(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::XorAssign(span: .span(start, .index))
		} else {
			.index += 1
			return Token::Xor(span: .span(start, .index))
		}
	}

	fn lexLess(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			if .source[.index + 2] == b'>' {
				.index += 3
				return Token::Spaceship(span: .span(start, .index))
			} else {
				.index += 2
				return Token::LessEqual(span: .span(start, .index))
			}
		} else {
			.index += 1
			return Token::LessThan(span: .span(start, .index))
		}
	}

	fn lexGreater(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::GreaterEqual(span: .span(start, .index))
		} else {
			.index += 1
			return Token::GreaterThan(span: .span(start, .index))
		}
	}

	fn lexNot(mut this) -> Token {
		let start = .index
		if .source[.index + 1] == b'=' {
			.index += 2
			return Token::NotEqual(span: .span(start, .index))
		} else {
			.index += 1
			return Token::LogicalNot(span: .span(start, .index))
		}
	}

	fn lexCharLiteral(mut this) throws -> Token {
		let start = .index
		.index++

		mut ch: u8 = 0
		if .source[.index] == b'\\' {
			.index++
			match .source[.index] {
				b'0' => { ch = b'\0' }
				b'a' => { ch = b'\a' }
				b'b' => { ch = b'\b' }
				b'e' => { ch = b'\e' }
				b'f' => { ch = b'\f' }
				b'n' => { ch = b'\n' }
				b'r' => { ch = b'\r' }
				b't' => { ch = b'\t' }
				b'v' => { ch = b'\v' }
				b'\\' => { ch = b'\\' }
				b'\'' => { ch = b'\'' }
				b'\"' => { ch = b'\"' }
				b'\?' => { ch = b'\?' }
				else => {
					.error("invalid escape sequence in char literal", Span(start: .index - 1, end: .index + 1))
				}
			}
		} else {
			ch = .source[.index]
		}
		.index++

		guard .source[.index] == b'\'' else {
			return Token::Unknown(span: .span(start, .index), ch: .source[.index])
		}
		.index++

		mut postfix = StringBuilder::create()
		while isAlphaOrDigit(.source[.index]) {
			postfix.append(.source[.index])
			.index++
		}

		let end = .index

		return Token::CharLiteral(span: .span(start, end), value: ch, postfix: postfix.to_string())
	}

	fn lexStringLiteral(mut this) throws -> Token {
		let start = .index
		.index++

		mut string_builder = StringBuilder::create()

		while .source[.index] != b'"' {
			if .source[.index] == b'\\' {
				.index++
				match .source[.index] {
					b'0' => string_builder.append(b'\0')
					b'a' => string_builder.append(b'\a')
					b'e' => string_builder.append(b'\e')
					b'b' => string_builder.append(b'\b')
					b'f' => string_builder.append(b'\f')
					b'n' => string_builder.append(b'\n')
					b'r' => string_builder.append(b'\r')
					b't' => string_builder.append(b'\t')
					b'v' => string_builder.append(b'\v')
					b'\\' => string_builder.append(b'\\')
					b'\'' => string_builder.append(b'\'')
					b'\"' => string_builder.append(b'\"')
					b'\?' => string_builder.append(b'\?')
					else => {
						.error("invalid escape sequence in string literal", Span(start: .index - 1, end: .index + 1))
					}
				}
			} else {
				string_builder.append(.source[.index])
			}
			.index++
		}
		.index++

		mut postfix = StringBuilder::create()
		while isAlphaOrDigit(.source[.index]) {
			postfix.append(.source[.index])
			.index++
		}

		let end = .index

		return Token::StringLiteral(span: .span(start, end), value: string_builder.to_string(), postfix: postfix.to_string())
	}

	fn lexNumberOrName(mut this) throws -> Token {
		let start = .index
		let ch = .source[.index]

		if isDigit(ch) {
			return .lexNumber()
		} else if isAlpha(ch) or (ch == b'_') or (ch >= 127) {
			return .lexName()
		} else {
			.error("unknown token", Span(start, end: .index + 1))
			return Token::Unknown(span: .span(start, .index++), ch: ch)
		}
	}

	fn lexNumber(mut this) throws -> Token {
		let start = .index
		mut length: usize = 0
		mut int_val = 0i64
		mut float_val = 0.0f64
		mut is_float = false

		unsafe {
			cpp {
				"
				const char *begin = (const char*)&source.at(index);
				char *int_end = nullptr;
				char *float_end = nullptr;

				int_val = strtol(begin, &int_end, 0);
				float_val = strtod(begin, &float_end);

				if (float_end > int_end + 1) {
					is_float = true;
					length = float_end - begin;
				} else {
					length = int_end - begin;
				}
				"
			}
		}

		.index += length

		mut postfix = StringBuilder::create()
		while isAlphaOrDigit(.source[.index]) {
			postfix.append(.source[.index])
			.index++
		}

		if is_float {
			return Token::FloatLiteral(span: .span(start, .index), value: float_val, postfix: postfix.to_string())
		} else {
			return Token::IntLiteral(span: .span(start, .index), value: int_val, postfix: postfix.to_string())
		}
	}

	fn lexName(mut this) throws -> Token {
		let start = .index

		while isAlphaOrDigit(.source[.index]) or (.source[.index] == b'_') or (.source[.index] >= 127) {
			.index++
		}

		let name = String::from_utf8(.source[start..(.index)].to_array())
		let span = .span(start, .index)

		return match name {
			"import" => Token::KeywordImport(span)
			"pragma" => Token::KeywordPragma(span)
			"extern" => Token::KeywordExtern(span)
			"func" => Token::KeywordFunc(span)
			"operator" => Token::KeywordOperator(span)
			"default" => Token::KeywordDefault(span)
			"template" => Token::KeywordTemplate(span)
			"struct" => Token::KeywordStruct(span)
			"enum" => Token::KeywordEnum(span)
			"variant" => Token::KeywordVariant(span)
			"extend" => Token::KeywordExtend(span)
			"public" => Token::KeywordPublic(span)
			"private" => Token::KeywordPrivate(span)
			"unsafe" => Token::KeywordUnsafe(span)
			"var" => Token::KeywordVar(span)
			"const" => Token::KeywordConst(span)
			"case" => Token::KeywordCase(span)
			"comptime" => Token::KeywordComptime(span)
			"is" => Token::KeywordIs(span)
			"as" => Token::KeywordAs(span)
			"unwrap" => Token::KeywordUnwrap(span)
			"if" => Token::KeywordIf(span)
			"else" => Token::KeywordElse(span)
			"for" => Token::KeywordFor(span)
			"in" => Token::KeywordIn(span)
			"while" => Token::KeywordWhile(span)
			"do" => Token::KeywordDo(span)
			"match" => Token::KeywordMatch(span)
			"continue" => Token::KeywordContinue(span)
			"break" => Token::KeywordBreak(span)
			"return" => Token::KeywordReturn(span)
			"discard" => Token::KeywordDiscard(span)
			"throw" => Token::KeywordThrow(span)
			"try" => Token::KeywordTry(span)
			"must" => Token::KeywordMust(span)
			"true" => Token::KeywordTrue(span)
			"false" => Token::KeywordFalse(span)
			else => Token::Identifier(span, name)
		}
	}
}
